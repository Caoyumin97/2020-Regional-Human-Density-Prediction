{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T13:09:26.026070Z",
     "start_time": "2020-03-11T13:09:25.808924Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(\"d:\\softwares\\python36\\lib\\site-packages\")\n",
    "from easyeda import eda\n",
    "from geohash import encode\n",
    "from geopy.distance import great_circle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Embedding, Dense, LeakyReLU, Input\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import KLD,categorical_crossentropy\n",
    "from tensorflow.keras.utils import normalize\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T12:56:42.471155Z",
     "start_time": "2020-03-11T12:56:42.460424Z"
    }
   },
   "outputs": [],
   "source": [
    "filedir = glob.glob(pathname='../Data/*.csv')\n",
    "filedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T12:56:42.575911Z",
     "start_time": "2020-03-11T12:56:42.474148Z"
    }
   },
   "outputs": [],
   "source": [
    "submit_table = pd.read_csv('../Data/submit_example/test_submit_example.csv', header=None)\n",
    "submit_data = submit_table.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## area info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T12:56:42.617787Z",
     "start_time": "2020-03-11T12:56:42.578870Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "area_passenger_info = pd.read_csv(filedir[1], header=None)\n",
    "area_passenger_info.columns = ['areaIdx', 'areaName', 'areaType', 'centerLon', 'centerLat',\n",
    "                               'gridLon', 'gridLat', 'coverage']\n",
    "area_passenger_info.info()\n",
    "\n",
    "# area type\n",
    "# 交通设施：0-2，旅游景点：3，教育培训：4，购物：5，医疗：6，运动健身：7\n",
    "areaTypes = area_passenger_info['areaType'].unique()\n",
    "normalTypes = {'旅游景点':3,'教育培训':4,'购物':5,'医疗':6,'运动健身':7}\n",
    "type_to_idx = {}\n",
    "idx = 0\n",
    "for item in areaTypes:\n",
    "    preType = re.match(\"(.*);(.*)\",item)[1]\n",
    "    if  preType == '交通设施':\n",
    "        type_to_idx[item] = idx\n",
    "        idx += 1\n",
    "    elif preType in normalTypes.keys():\n",
    "        type_to_idx[item] = normalTypes[preType]\n",
    "    else:\n",
    "        print(\"this type does not exist.\")\n",
    "\n",
    "area_passenger_info['areaType'] = area_passenger_info['areaType'].replace(type_to_idx)\n",
    "area_passenger_info['radius'] = np.sqrt(area_passenger_info['coverage'])\n",
    "area_passenger_info['coverage'] = area_passenger_info['coverage'] / 4e+4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T12:56:42.660934Z",
     "start_time": "2020-03-11T12:56:42.622757Z"
    }
   },
   "outputs": [],
   "source": [
    "area_passenger_info['coord'] = area_passenger_info.apply(lambda x: (x['centerLat'],\n",
    "                                                                    x['centerLon']),\n",
    "                                                         axis=1)\n",
    "CBDcoord = (39.91178273927437, 116.4015680859375)\n",
    "area_passenger_info['cbdDist'] = area_passenger_info['coord'].map(\n",
    "    lambda x: great_circle(CBDcoord, x).km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T12:56:58.987123Z",
     "start_time": "2020-03-11T12:56:42.662649Z"
    }
   },
   "outputs": [],
   "source": [
    "num_areas = len(area_passenger_info)\n",
    "distance = np.zeros((num_areas, num_areas))\n",
    "for i in range(num_areas):\n",
    "    a = area_passenger_info['coord'][int(i)]\n",
    "    for j in range(num_areas):\n",
    "        if j >= i:\n",
    "            break\n",
    "        b = area_passenger_info['coord'][int(j)]\n",
    "        distance[i, j] = great_circle(a,b).km\n",
    "area_distance = distance.T + distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T12:57:00.598682Z",
     "start_time": "2020-03-11T12:56:58.989132Z"
    }
   },
   "outputs": [],
   "source": [
    "area_passenger_info['avgDistance'] = area_distance.sum(axis = 1) / (num_areas - 1)\n",
    "\n",
    "std = np.zeros((num_areas,1))\n",
    "num_inc_areas = np.zeros((num_areas,1))\n",
    "closest_five = np.zeros((num_areas,5))\n",
    "closest_five_dist = np.zeros((num_areas,5))\n",
    "for i in range(num_areas):\n",
    "    # rm zeros\n",
    "    base_rm = list(set(area_distance[i,:]) - {0})\n",
    "    radius = area_passenger_info['radius'].iloc[i]\n",
    "    num_inc_areas[i,:] = np.sum(base_rm <= radius / 1000)\n",
    "    std = np.std(base_rm)\n",
    "    for j in range(5):\n",
    "        closest_five[i,j] = np.argmin(base_rm)\n",
    "        closest_five_dist[i,j] = np.min(base_rm)\n",
    "        base_rm.remove(np.min(base_rm))\n",
    "\n",
    "area_passenger_info['stdDistance'] = std\n",
    "area_passenger_info['numIncludeAreas'] = num_inc_areas\n",
    "for j in range(5):\n",
    "    area_passenger_info['closestNo_' + str(j + 1)] = closest_five[:,j]\n",
    "    area_passenger_info['closestDistNo_' + str(j + 1)] = closest_five_dist[:,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T12:57:00.629716Z",
     "start_time": "2020-03-11T12:57:00.598682Z"
    }
   },
   "outputs": [],
   "source": [
    "area_passenger_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## index-stats embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T12:57:02.564285Z",
     "start_time": "2020-03-11T12:57:00.631707Z"
    }
   },
   "outputs": [],
   "source": [
    "area_passenger_ind = pd.read_csv(filedir[0],header = None)\n",
    "area_passenger_ind.columns = ['areaIdx','datetime','Density']\n",
    "area_passenger_ind['datetime'] = pd.to_datetime(area_passenger_ind['datetime'],format=\"%Y%m%d%H\")\n",
    "area_passenger_ind.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T12:57:16.029186Z",
     "start_time": "2020-03-11T12:57:02.566287Z"
    }
   },
   "outputs": [],
   "source": [
    "area_passenger_ind['ToD'] = area_passenger_ind['datetime'].map(lambda x: x.hour)\n",
    "area_passenger_ind['DoW'] = area_passenger_ind['datetime'].map(lambda x: x.weekday())\n",
    "embed_data = pd.merge(area_passenger_ind, area_passenger_info, on='areaIdx')\n",
    "area_passenger_ind = pd.merge(area_passenger_ind,\n",
    "                              area_passenger_info[['areaIdx', 'areaType']],\n",
    "                              on='areaIdx')\n",
    "\n",
    "\n",
    "def trend(x):\n",
    "    return np.mean(pd.Series(x).diff().fillna(0))\n",
    "\n",
    "\n",
    "area_type_label = area_passenger_ind.pivot_table(index='areaType',\n",
    "                                                 columns='ToD',\n",
    "                                                 values='Density',\n",
    "                                                 aggfunc=['mean', 'std', 'median', trend])\n",
    "area_passenger_info = pd.merge(area_passenger_info,\n",
    "                               area_type_label,\n",
    "                               on='areaType')\n",
    "area_passenger_ind.drop('areaType', axis=1, inplace=True)\n",
    "embed_label = area_passenger_ind.pivot_table(index='areaIdx',\n",
    "                                             columns='ToD',\n",
    "                                             values='Density',\n",
    "                                             aggfunc=['mean', 'std', 'median', np.ptp, trend])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T12:57:16.037355Z",
     "start_time": "2020-03-11T12:57:16.031232Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_embedding(embedding_dim, batch_size, epochs):\n",
    "    # build model\n",
    "    x = Input(shape=(1,))\n",
    "    o = Embedding(input_dim=997, output_dim=embedding_dim,\n",
    "                  embeddings_initializer=he_normal(), name='embedding')(x)\n",
    "    h = Dense(128, use_bias=False,\n",
    "              kernel_initializer=he_normal(), activation='relu')(o)\n",
    "    h = Dense(24 * 5, use_bias=False,\n",
    "              kernel_initializer=he_normal(), activation='relu')(o)\n",
    "    model = Model(inputs=x, outputs=h)\n",
    "    model.compile(loss='mse', optimizer=Adam(3e-4))\n",
    "    \n",
    "    # train embedding weights\n",
    "    hist = model.fit(np.arange(0, 997).reshape(-1, 1), normalize(embed_label.values),\n",
    "                 batch_size=batch_size, epochs=epochs, shuffle=True, verbose=0)\n",
    "    \n",
    "    # output embedding vector\n",
    "    areaEmbedding = model.get_weights()[0]\n",
    "    \n",
    "    return areaEmbedding, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T12:57:44.412852Z",
     "start_time": "2020-03-11T12:57:16.040349Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_dim = 20\n",
    "areaEmbedding, trainingLog = get_embedding(embedding_dim=embedding_dim,\n",
    "                                           batch_size=16,epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historic index (same area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T12:57:44.424228Z",
     "start_time": "2020-03-11T12:57:44.412852Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_hitoric_index(area_passenger_ind, window_size, num_samples, num_areas, num_days):\n",
    "    \n",
    "    # init\n",
    "    historicIndex = np.zeros((num_samples, window_size))\n",
    "    sample_idx = 0\n",
    "    sp = time.time()\n",
    "    \n",
    "    # main loop\n",
    "    for area_idx in range(1, num_areas + 1):\n",
    "        if area_idx % 200 == 0:\n",
    "            print(\"[Area-{:d}] started, duration: {:.1f} sec.\".format(area_idx, time.time() - sp))\n",
    "        area_df = area_passenger_ind[area_passenger_ind.areaIdx == area_idx]\n",
    "        for i in range(24 * num_days - window_size):\n",
    "            historicIndex[sample_idx] = area_df['Density'].values[i:i + window_size]\n",
    "            sample_idx += 1\n",
    "    \n",
    "    return historicIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T12:57:47.914768Z",
     "start_time": "2020-03-11T12:57:44.428215Z"
    }
   },
   "outputs": [],
   "source": [
    "# params\n",
    "window_size = 8\n",
    "num_areas = 997\n",
    "num_days = 30\n",
    "num_samples = (24 * num_days - window_size)  * num_areas\n",
    "\n",
    "# get historic index\n",
    "historicIndex = get_hitoric_index(area_passenger_ind,\n",
    "                                  window_size=window_size,\n",
    "                                  num_samples=num_samples,\n",
    "                                  num_areas=num_areas,\n",
    "                                  num_days=num_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T12:57:48.231365Z",
     "start_time": "2020-03-11T12:57:47.916878Z"
    }
   },
   "outputs": [],
   "source": [
    "histMean = historicIndex.mean(axis=1)\n",
    "histStd = historicIndex.std(axis=1)\n",
    "histMedian = np.median(historicIndex, axis=1)\n",
    "histPtp = np.ptp(historicIndex, axis=1)\n",
    "histDiff = historicIndex[:,1:] - historicIndex[:,:(window_size - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T12:57:48.379254Z",
     "start_time": "2020-03-11T12:57:48.233250Z"
    }
   },
   "outputs": [],
   "source": [
    "historicIndexDf = pd.DataFrame()\n",
    "\n",
    "for col in range(window_size):\n",
    "    historicIndexDf['historic_' + str(col)] = historicIndex[:,col]\n",
    "\n",
    "for col in range(window_size - 1):\n",
    "    historicIndexDf['historic_diff_' + str(col)] = histDiff[:,col]\n",
    "\n",
    "historicIndexDf['histMean'] = histMean\n",
    "historicIndexDf['histStd'] = histStd\n",
    "historicIndexDf['histMedian'] = histMedian\n",
    "historicIndexDf['histPtp'] = histPtp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T12:57:48.393174Z",
     "start_time": "2020-03-11T12:57:48.381372Z"
    }
   },
   "outputs": [],
   "source": [
    "areaEmbeddingDf = pd.DataFrame(np.arange(1,num_areas + 1),columns=['areaIdx'])\n",
    "for col in range(embedding_dim):\n",
    "    areaEmbeddingDf[\"embedding_\" + str(col)] = areaEmbedding[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T12:57:48.418137Z",
     "start_time": "2020-03-11T12:57:48.402146Z"
    }
   },
   "outputs": [],
   "source": [
    "areaAttr = pd.merge(area_passenger_info, areaEmbeddingDf, on='areaIdx')\n",
    "areaAttr.drop(['areaName','coord'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T12:57:52.339514Z",
     "start_time": "2020-03-11T12:57:48.421128Z"
    }
   },
   "outputs": [],
   "source": [
    "dfs = [area_passenger_ind, areaAttr, embed_label.reset_index()]\n",
    "AreaDensity = reduce(lambda a,b:pd.merge(a,b,on='areaIdx'),dfs)\n",
    "AreaDensity.drop(\"datetime\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T13:08:29.272176Z",
     "start_time": "2020-03-11T12:59:59.759521Z"
    }
   },
   "outputs": [],
   "source": [
    "# init\n",
    "X_attr = np.zeros((num_samples,AreaDensity.shape[1]))\n",
    "sample_idx = 0\n",
    "sp = time.time()\n",
    "\n",
    "# main loop\n",
    "for area_idx in range(1, num_areas + 1):\n",
    "    if area_idx % 200 == 0:\n",
    "        print(\"[Area-{:d}] started, duration: {:.1f} sec.\".format(area_idx, time.time() - sp))\n",
    "    area_df = AreaDensity[AreaDensity.areaIdx == area_idx]\n",
    "    for i in range(window_size, 24 * num_days):\n",
    "        X_attr[sample_idx] = area_df.values[i,:]\n",
    "        sample_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T13:09:11.416677Z",
     "start_time": "2020-03-11T13:08:59.917180Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.concat((pd.DataFrame(X_attr, columns=AreaDensity.columns),\n",
    "               historicIndexDf), axis=1)\n",
    "del X_attr, AreaDensity\n",
    "Y_data = X['Density']\n",
    "X_data = X.drop(['Density'], axis=1)\n",
    "del X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T13:08:38.435408Z",
     "start_time": "2020-03-11T13:02:07.776Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\":\"regression\",\n",
    "    \"num_rounds\":10000,\n",
    "    \"learning_rate\":0.01,\n",
    "    \"max_depth\":9,\n",
    "    \"num_leaves\":100,\n",
    "    \"feature_fraction\":0.8,\n",
    "    \"verbose\":2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T13:08:38.442364Z",
     "start_time": "2020-03-11T13:02:08.282Z"
    }
   },
   "outputs": [],
   "source": [
    "def score(y_pred, y_test):\n",
    "    rmse = np.sqrt(np.mean(np.square(y_pred - y_test)))\n",
    "    return 1/(1 + rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5,shuffle=True)\n",
    "idx = 0\n",
    "for train_idx, test_idx in kf.split(X_data):\n",
    "    # dataset split\n",
    "    X_train, y_train = X_data.iloc[train_idx], Y_data.iloc[train_idx]\n",
    "    X_test, y_test = X_data.iloc[test_idx], Y_data.iloc[test_idx]\n",
    "    \n",
    "    # train\n",
    "    categorical_features = ['areaIdx','ToD', 'DoW', 'areaType',\n",
    "                            'closestNo_1','closestNo_2','closestNo_3',\n",
    "                            'closestNo_4','closestNo_5']\n",
    "    train_data = lgb.Dataset(X_train,y_train,categorical_feature=categorical_features)\n",
    "    test_data = lgb.Dataset(X_test,y_test,reference=train_data)\n",
    "    \n",
    "    gbm = lgb.train(params,train_data)\n",
    "    y_pred = gbm.predict(X_test,num_iteration=gbm.best_iteration)\n",
    "    print(\"[CV-{:d}] score: {:.4f}\".format(idx, score(y_pred,y_test)))\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(gbm,max_num_features = 30, height = 0.5,figsize=(10,8),grid = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Auto-aggressive prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = submit_table.copy()\n",
    "X_test.columns = ['areaIdx','datetime','predIndex']\n",
    "\n",
    "X_test['datetime'] = pd.to_datetime(X_test['datetime'],format=\"%Y%m%d%H\")\n",
    "X_test['ToD'] = X_test['datetime'].map(lambda x: x.hour)\n",
    "X_test['DoW'] = X_test['datetime'].map(lambda x: x.weekday())\n",
    "\n",
    "dfs = [X_test,area_passenger_info,areaEmbeddingDf]\n",
    "X_test = reduce(lambda a,b:pd.merge(a,b,on='areaIdx'),dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historic_feature(values, window_size):\n",
    "    historic_ = values[-window_size:]\n",
    "    historic_diff_ = np.array(historic_[-window_size + 1:]) - np.array(historic_[-window_size:-1])\n",
    "    histMean = np.mean(historic_)\n",
    "    histStd = np.std(historic_)\n",
    "    histMedian = np.median(historic_)\n",
    "    histPtp = np.ptp(historic_)\n",
    "    return historic_ + historic_diff_.tolist() + [histMean,histStd,histMedian,histPtp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = X_test.drop([\"datetime\",\"predIndex\",\"areaName\"],axis = 1)\n",
    "sample_idx = 0\n",
    "sp = time.time()\n",
    "for areaIdx in range(1, 1 + num_areas):\n",
    "    X_test_area = X_test[X_test.areaIdx == areaIdx]\n",
    "    histValues = area_passenger_ind[area_passenger_ind.areaIdx == areaIdx]['Density'].values.tolist()\n",
    "    for i in range(len(X_test_area)):\n",
    "        # predict\n",
    "        histFeat = get_historic_feature(histValues,window_size=window_size)\n",
    "        test_sample_input = test_input.iloc[i,:].tolist() + histFeat + test_svd\n",
    "        pred_value = gbm.predict([test_sample_input])[0]\n",
    "        \n",
    "        # update submit file\n",
    "        submit_table.iloc[sample_idx,2] = pred_value\n",
    "        \n",
    "        # update aggressive base\n",
    "        histValues.append(pred_value)\n",
    "        sample_idx += 1\n",
    "        \n",
    "    print(\"[Area-{:d}] Finished. Duration: {:.1f} sec.\".format(areaIdx,time.time() - sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_table.to_csv('../Data/submit_files/',header=None,index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "473.545px",
    "left": "1026.36px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
